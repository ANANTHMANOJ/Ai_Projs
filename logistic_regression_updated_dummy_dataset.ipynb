{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "logistic regression-updated_dummy_dataset.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ANANTHMANOJ/Ai_Projs/blob/master/logistic_regression_updated_dummy_dataset.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwXOVvMW64wT"
      },
      "source": [
        "import numpy as np \n",
        "import seaborn as sns\n",
        "sns.set(style='whitegrid')\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import torch\n",
        "from torch import autograd"
      ],
      "execution_count": 307,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FNylIyKlXuRN",
        "outputId": "0c96be28-b430-472f-dc3d-1d992ddfff87"
      },
      "source": [
        "data = pd.read_csv(\"Iris.csv\")\n",
        "data.Species.unique()"
      ],
      "execution_count": 308,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['Iris-setosa', 'Iris-versicolor', 'Iris-virginica'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 308
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CReGgiueyJbA",
        "outputId": "a218d634-d0d4-47be-b0f9-fdf19f00ec30"
      },
      "source": [
        "data.shape"
      ],
      "execution_count": 309,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(150, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 309
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VH7p9lP-X8YU"
      },
      "source": [
        "data.Species = data.Species.replace(to_replace=['Iris-setosa', 'Iris-versicolor','Iris-virginica'], value=[0, 1, 2])"
      ],
      "execution_count": 310,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JkNtYRvlYQjt"
      },
      "source": [
        "X = data.drop(labels=['Id', 'Species'], axis=1).values\n",
        "y = data.Species.values"
      ],
      "execution_count": 311,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YfBXL_hZYLhM",
        "outputId": "c4df0942-7eaf-476a-a32e-c246b560baea"
      },
      "source": [
        "y"
      ],
      "execution_count": 312,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
              "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 312
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPmcr-weYmBt"
      },
      "source": [
        "seed = 5\n",
        "np.random.seed(seed)\n",
        "tf.random.set_seed(seed)"
      ],
      "execution_count": 313,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PeoHF-mye-8j"
      },
      "source": [
        "train_index = np.random.choice(len(X), round(len(X) * 0.8), replace=False)"
      ],
      "execution_count": 314,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1j0XJZwfC83"
      },
      "source": [
        "test_index = np.array(list(set(range(len(X))) - set(train_index)))\n",
        "train_X = X[train_index]\n",
        "train_y = y[train_index]\n",
        "test_X = X[test_index]\n",
        "test_y = y[test_index]"
      ],
      "execution_count": 315,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cH8PfmT6fFoO"
      },
      "source": [
        "def min_max_normalized(data):\n",
        "    col_max = np.max(data, axis=0)\n",
        "    col_min = np.min(data, axis=0)\n",
        "    return np.divide(data - col_min, col_max - col_min)"
      ],
      "execution_count": 316,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDodv8r9fIPM"
      },
      "source": [
        "train_X = min_max_normalized(train_X)\n",
        "test_X = min_max_normalized(test_X)"
      ],
      "execution_count": 317,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pHlPD6xxjwIu"
      },
      "source": [
        "train_X = torch.tensor(train_X)\n",
        "train_y = torch.tensor(train_y)\n",
        "test_X = torch.tensor(test_X)\n",
        "test_y = torch.tensor(test_y)"
      ],
      "execution_count": 318,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gMG2XMJsi0x0",
        "outputId": "f546aa60-6abe-488b-ee9a-d45b22a949a5"
      },
      "source": [
        "W = torch.rand(size=(4, 3),requires_grad=True)\n",
        "b = torch.rand(3, requires_grad=True)\n",
        "params = [W, b]\n",
        "params"
      ],
      "execution_count": 319,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[0.6383, 0.2983, 0.1608],\n",
              "         [0.0198, 0.2852, 0.6497],\n",
              "         [0.3888, 0.2868, 0.5106],\n",
              "         [0.5584, 0.8322, 0.9047]], requires_grad=True),\n",
              " tensor([0.7580, 0.6612, 0.5667], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 319
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vJkgW3NOklT1"
      },
      "source": [
        "def softmax(y_linear):\n",
        "    exp = torch.exp(y_linear-torch.max(y_linear))\n",
        "    norms = torch.sum(exp, axis=1).reshape((-1,1))\n",
        "    return exp / norms"
      ],
      "execution_count": 320,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HelA2w_wlAWN",
        "outputId": "71325f65-cced-47c9-b24b-97bcd4b0a684"
      },
      "source": [
        "sample_y_linear = torch.rand(size=(4,3))\n",
        "sample_yhat = softmax(sample_y_linear)\n",
        "print(sample_yhat)"
      ],
      "execution_count": 321,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.3898, 0.2706, 0.3396],\n",
            "        [0.3401, 0.2692, 0.3907],\n",
            "        [0.4189, 0.3201, 0.2611],\n",
            "        [0.2708, 0.3523, 0.3769]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KCRQPZvZlfvR",
        "outputId": "bf090274-cd02-4466-9ad5-ec65f17f8e31"
      },
      "source": [
        "torch.sum(sample_yhat,axis=1)"
      ],
      "execution_count": 322,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0000, 1.0000, 1.0000, 1.0000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 322
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yFpu-4RCmfkc"
      },
      "source": [
        "def net(X):\n",
        "    y_linear = torch.mm(X, W) + b\n",
        "    yhat = softmax(y_linear)\n",
        "    return yhat"
      ],
      "execution_count": 323,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g0gQY4SUmsRK"
      },
      "source": [
        "def cross_entropy(yhat, y):\n",
        "    return - torch.sum(y * torch.log(yhat+1e-6))"
      ],
      "execution_count": 324,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7YImdHVAm8sz"
      },
      "source": [
        "def SGD(params, lr):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad\n"
      ],
      "execution_count": 325,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qkHrPxVo5UR"
      },
      "source": [
        "def one_hot_encode(vector):\n",
        "    n_classes = len(vector.unique())\n",
        "    one_hot = torch.zeros((vector.shape[0], n_classes)).type(torch.LongTensor)\n",
        "    return one_hot.scatter(1, vector.type(torch.LongTensor).unsqueeze(1), 1)"
      ],
      "execution_count": 326,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NItjmY3JnvkI"
      },
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=list(zip(train_X,train_y)), batch_size=50, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(dataset=list(zip(test_X,test_y)), batch_size=50, shuffle=False)"
      ],
      "execution_count": 327,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VQZ8BQ6pob_h"
      },
      "source": [
        "def evaluate_accuracy(data_iterator, net):\n",
        "    numerator = 0.\n",
        "    denominator = 0.\n",
        "    for i, (data, label) in enumerate(data_iterator):\n",
        "        data = data\n",
        "        label = label\n",
        "        label_one_hot = one_hot_encode(label)\n",
        "        output = net(data.float())\n",
        "        predictions = torch.argmax(output, axis=1)\n",
        "        numerator += torch.sum(predictions == label)\n",
        "        denominator += data.shape[0]\n",
        "    return (numerator / denominator)"
      ],
      "execution_count": 328,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Prg-eST1pOuQ",
        "outputId": "0335d4a9-d088-444d-bbb9-6387891cebc4"
      },
      "source": [
        "evaluate_accuracy(test_loader, net)\n"
      ],
      "execution_count": 329,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 329
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WPZBhjfe7Lm0",
        "outputId": "4042b957-b48e-4176-e35e-32322afb03d0"
      },
      "source": [
        "learning_rate = .005\n",
        "epochs = 150\n",
        "for e in range(epochs):\n",
        "    cumulative_loss = 0\n",
        "    for i, (data, label) in enumerate(train_loader):\n",
        "        label_one_hot =one_hot_encode(label)\n",
        "        #with autograd.:\n",
        "        output = net(data.float())\n",
        "        loss = cross_entropy(output, label_one_hot)\n",
        "        loss.backward()\n",
        "        with torch.no_grad():\n",
        "          SGD(params, learning_rate)\n",
        "\n",
        "        cumulative_loss += torch.sum(loss)\n",
        "\n",
        "\n",
        "    test_accuracy = evaluate_accuracy(test_loader, net)\n",
        "    train_accuracy = evaluate_accuracy(train_loader, net)\n",
        "    print(\"Epoch %s. Loss: %.6s, Train_acc %.6s, Test_acc %.6s\" % (e, float(cumulative_loss)/50, float(train_accuracy), float(test_accuracy)))"
      ],
      "execution_count": 330,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 0. Loss: 2.6148, Train_acc 0.4833, Test_acc 0.6000\n",
            "Epoch 1. Loss: 2.3843, Train_acc 0.8916, Test_acc 0.8999\n",
            "Epoch 2. Loss: 2.0312, Train_acc 0.9333, Test_acc 0.8666\n",
            "Epoch 3. Loss: 1.6857, Train_acc 0.7916, Test_acc 0.8000\n",
            "Epoch 4. Loss: 1.3482, Train_acc 0.9250, Test_acc 0.8999\n",
            "Epoch 5. Loss: 1.1254, Train_acc 0.9166, Test_acc 0.8999\n",
            "Epoch 6. Loss: 0.9612, Train_acc 0.9416, Test_acc 0.9333\n",
            "Epoch 7. Loss: 0.8457, Train_acc 0.9250, Test_acc 0.9333\n",
            "Epoch 8. Loss: 0.7477, Train_acc 0.9333, Test_acc 0.9333\n",
            "Epoch 9. Loss: 0.6686, Train_acc 0.9333, Test_acc 0.9333\n",
            "Epoch 10. Loss: 0.6006, Train_acc 0.9499, Test_acc 0.8999\n",
            "Epoch 11. Loss: 0.5492, Train_acc 0.9499, Test_acc 0.8999\n",
            "Epoch 12. Loss: 0.5089, Train_acc 0.9499, Test_acc 0.9333\n",
            "Epoch 13. Loss: 0.4655, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 14. Loss: 0.4332, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 15. Loss: 0.4067, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 16. Loss: 0.3858, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 17. Loss: 0.3634, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 18. Loss: 0.3471, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 19. Loss: 0.3292, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 20. Loss: 0.3196, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 21. Loss: 0.3053, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 22. Loss: 0.2931, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 23. Loss: 0.2819, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 24. Loss: 0.2754, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 25. Loss: 0.2657, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 26. Loss: 0.2592, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 27. Loss: 0.2502, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 28. Loss: 0.2427, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 29. Loss: 0.2375, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 30. Loss: 0.2330, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 31. Loss: 0.2281, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 32. Loss: 0.2225, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 33. Loss: 0.2178, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 34. Loss: 0.2099, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 35. Loss: 0.2090, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 36. Loss: 0.2032, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 37. Loss: 0.2005, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 38. Loss: 0.1969, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 39. Loss: 0.1919, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 40. Loss: 0.1899, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 41. Loss: 0.1874, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 42. Loss: 0.1839, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 43. Loss: 0.1824, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 44. Loss: 0.1806, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 45. Loss: 0.1774, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 46. Loss: 0.1755, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 47. Loss: 0.1707, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 48. Loss: 0.1697, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 49. Loss: 0.1696, Train_acc 0.9499, Test_acc 0.9666\n",
            "Epoch 50. Loss: 0.1668, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 51. Loss: 0.1652, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 52. Loss: 0.1629, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 53. Loss: 0.1610, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 54. Loss: 0.1589, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 55. Loss: 0.1588, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 56. Loss: 0.1548, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 57. Loss: 0.1578, Train_acc 0.9583, Test_acc 0.9666\n",
            "Epoch 58. Loss: 0.1546, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 59. Loss: 0.1536, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 60. Loss: 0.1516, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 61. Loss: 0.1509, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 62. Loss: 0.1485, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 63. Loss: 0.1482, Train_acc 0.9666, Test_acc 0.9666\n",
            "Epoch 64. Loss: 0.1475, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 65. Loss: 0.1456, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 66. Loss: 0.1459, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 67. Loss: 0.1448, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 68. Loss: 0.1436, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 69. Loss: 0.1445, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 70. Loss: 0.1422, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 71. Loss: 0.1418, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 72. Loss: 0.1427, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 73. Loss: 0.1401, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 74. Loss: 0.1403, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 75. Loss: 0.1403, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 76. Loss: 0.1404, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 77. Loss: 0.1399, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 78. Loss: 0.1389, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 79. Loss: 0.1387, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 80. Loss: 0.1380, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 81. Loss: 0.1387, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 82. Loss: 0.1402, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 83. Loss: 0.1393, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 84. Loss: 0.1409, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 85. Loss: 0.1399, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 86. Loss: 0.1403, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 87. Loss: 0.1402, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 88. Loss: 0.1423, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 89. Loss: 0.1389, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 90. Loss: 0.1403, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 91. Loss: 0.1411, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 92. Loss: 0.1413, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 93. Loss: 0.1420, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 94. Loss: 0.1435, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 95. Loss: 0.1436, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 96. Loss: 0.1434, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 97. Loss: 0.1444, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 98. Loss: 0.1439, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 99. Loss: 0.1438, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 100. Loss: 0.1454, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 101. Loss: 0.1454, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 102. Loss: 0.1461, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 103. Loss: 0.1470, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 104. Loss: 0.1484, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 105. Loss: 0.1498, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 106. Loss: 0.1495, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 107. Loss: 0.1497, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 108. Loss: 0.1512, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 109. Loss: 0.1511, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 110. Loss: 0.1512, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 111. Loss: 0.1527, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 112. Loss: 0.1553, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 113. Loss: 0.1553, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 114. Loss: 0.1568, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 115. Loss: 0.1572, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 116. Loss: 0.1577, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 117. Loss: 0.1592, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 118. Loss: 0.1600, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 119. Loss: 0.1590, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 120. Loss: 0.1603, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 121. Loss: 0.1618, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 122. Loss: 0.1619, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 123. Loss: 0.1632, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 124. Loss: 0.1641, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 125. Loss: 0.1658, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 126. Loss: 0.1668, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 127. Loss: 0.1668, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 128. Loss: 0.1675, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 129. Loss: 0.1673, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 130. Loss: 0.1686, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 131. Loss: 0.1710, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 132. Loss: 0.1697, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 133. Loss: 0.1713, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 134. Loss: 0.1721, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 135. Loss: 0.1742, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 136. Loss: 0.1739, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 137. Loss: 0.1748, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 138. Loss: 0.1759, Train_acc 0.9750, Test_acc 0.9666\n",
            "Epoch 139. Loss: 0.1769, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 140. Loss: 0.1775, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 141. Loss: 0.1785, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 142. Loss: 0.1786, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 143. Loss: 0.1793, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 144. Loss: 0.1817, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 145. Loss: 0.1829, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 146. Loss: 0.1822, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 147. Loss: 0.1833, Train_acc 0.9833, Test_acc 0.9666\n",
            "Epoch 148. Loss: 0.1847, Train_acc 0.9833, Test_acc 1.0\n",
            "Epoch 149. Loss: 0.1857, Train_acc 0.9833, Test_acc 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8tGcjR8rJUeJ",
        "outputId": "e4239ca7-168d-4825-ec78-c3f6eb8799a7"
      },
      "source": [
        "params"
      ],
      "execution_count": 331,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[tensor([[ -49.0244,   24.4024,   25.7194],\n",
              "         [  84.2513,  -11.7738,  -71.5225],\n",
              "         [-108.7943,    0.8393,  109.1417],\n",
              "         [-105.7495,  -10.8288,  118.8734]], requires_grad=True),\n",
              " tensor([ 51.2962,  44.9304, -94.2407], requires_grad=True)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 331
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EM5vWh8zHSt5"
      },
      "source": [
        "y_one_hot = one_hot_encode(train_y)"
      ],
      "execution_count": 332,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tsNGwrAVD7es",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b8fcf3c-2fb8-414a-f9e5-18c0c0d65104"
      },
      "source": [
        "def model_predict(net,data):\n",
        "    output = net(data.float())\n",
        "    return torch.argmax(output, axis=1)\n",
        "\n",
        "sample_data = torch.utils.data.DataLoader(dataset=list(zip(train_X,train_y)), batch_size=5, shuffle=True)\n",
        "for i, (data, label) in enumerate(sample_data):\n",
        "    print(data.shape)\n",
        "    pred=model_predict(net,data)\n",
        "    print('model predictions are:', pred)\n",
        "    print('Real values are : ',label)\n",
        "    break"
      ],
      "execution_count": 333,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([5, 4])\n",
            "model predictions are: tensor([0, 1, 1, 0, 1])\n",
            "Real values are :  tensor([0, 1, 1, 0, 1])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sStfwBBkD7Jg"
      },
      "source": [
        ""
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sUnl9ZuD6fV"
      },
      "source": [
        ""
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "47kYpwLgD4oP"
      },
      "source": [
        ""
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2w1LFYRwD33c"
      },
      "source": [
        ""
      ],
      "execution_count": 333,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c6BXLu6g64wk"
      },
      "source": [
        ""
      ],
      "execution_count": 333,
      "outputs": []
    }
  ]
}